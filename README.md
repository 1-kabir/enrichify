# Enrichify ğŸ”âœ¨

**Open-source, multi-agent data enrichment for leads and professional data.**

Turn raw web data into **verified, structured, and actionable** leadsâ€”using **any search provider** (Exa, Tavily, Brave, etc.) with **Bring Your Own Key (BYOK)** support.

---

## ğŸš€ **What is Enrichify?**

Enrichify is a **scalable, self-hostable** system for:
- **Enriching leads** (emails, social profiles, company data)
- **Aggregating search results** from multiple providers
- **Processing with AI/LLM** for data verification and enrichment
- **Bring Your Own Key (BYOK)** â€“ Use your existing API keys for any provider

**100% open-source** â€“ No locked features. Deploy anywhere.

---

## ğŸ› ï¸ **Features**

âœ… **Multi-Provider Search** â€“ Exa, Tavily, Brave, Serper, SearXNG, or add your own  
âœ… **Multi-Provider LLM** â€“ OpenAI, Claude, Gemini, Groq, Mistral, OpenRouter, or custom  
âœ… **Bring Your Own Key (BYOK)** â€“ Securely use your API keys  
âœ… **Queue System** â€“ Async job processing with retries (BullMQ)  
âœ… **Real-time Chat** â€“ WebSocket-powered conversations  
âœ… **Data Export** â€“ CSV, JSON, and custom formats  
âœ… **Self-Hostable** â€“ Run locally or deploy with Docker  
âœ… **Extensible** â€“ Add new providers in minutes  

---

## ğŸ¤– **Supported Providers**

### LLM Providers
Built-in exclusive integrations:
- **OpenAI** (GPT-4, GPT-3.5)
- **Anthropic Claude** (Claude 3 Opus, Sonnet, Haiku)
- **Google Gemini** (Pro)
- **Groq** (Mixtral, LLaMA)
- **Mistral** (Mistral Large)
- **OpenRouter** (Multi-model proxy)
- **OpenAI-compatible** (Local models, vLLM, etc.)

### Search Providers
Built-in integrations:
- **Exa** â€“ AI-powered semantic search
- **Tavily** â€“ Search & research API
- **Brave Search** â€“ Privacy-focused search
- **Serper** â€“ Google search API
- **SearXNG** â€“ Self-hosted metasearch engine

> **Want to add a custom provider?** See [Adding LLM Providers](docs/development/ADDING_LLM_PROVIDERS.md) or [Adding Search Providers](docs/development/ADDING_SEARCH_PROVIDERS.md).

---

## ğŸ“ **Project Structure**

```
enrichify/
â”œâ”€â”€ frontend/                   # Next.js React application
â”‚   â”œâ”€â”€ app/                    # App Router pages
â”‚   â”œâ”€â”€ components/             # Reusable UI components
â”‚   â”œâ”€â”€ lib/                    # Utility functions & API client
â”‚   â””â”€â”€ package.json
â”œâ”€â”€ backend/                    # NestJS API server
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ modules/            # Feature modules (auth, chat, websets, etc.)
â”‚   â”‚   â”œâ”€â”€ providers/          # LLM & Search provider integrations
â”‚   â”‚   â”œâ”€â”€ entities/           # TypeORM database entities
â”‚   â”‚   â””â”€â”€ main.ts             # Application entry point
â”‚   â””â”€â”€ package.json
â”œâ”€â”€ shared/                     # Shared types/interfaces
â”œâ”€â”€ docker/                     # Docker configurations
â”œâ”€â”€ docs/                       # Developer & contribution guides
â”œâ”€â”€ config.yml.example          # Configuration template
â”œâ”€â”€ .env.example                # Environment variables template
â””â”€â”€ docker-compose.yml          # Local development orchestration
```

---

## ğŸš€ **Quick Start**

### Prerequisites

Before starting, ensure you have:
- Docker and Docker Compose installed
- API keys for at least one LLM provider (OpenAI, Anthropic, etc.)
- API keys for at least one search provider (Tavily, Exa, etc.)

### Understanding the BYOK Model

Enrichify uses a **Bring Your Own Key (BYOK)** model, meaning you provide your own API keys for LLM and search providers. This ensures:
- You maintain control over your API usage and billing
- No third-party access to your API keys
- Direct payment to providers for services used

### Using Docker Compose (Recommended)

```bash
# Clone the repository
git clone <repository-url>
cd enrichify

# Create environment file
cp .env.example .env

# Edit .env and add your API keys
# See detailed configuration below
nano .env

# Start all services
docker-compose up -d

# Access the application
# Frontend: http://localhost:8080
# Backend API: http://localhost:3001
```

> For detailed setup instructions, see [Quick Start Guide](docs/guides/QUICKSTART.md)

### Configuration Guide

#### Required Environment Variables

**Database Configuration:**
- `DATABASE_URL`: PostgreSQL connection string
- `POSTGRES_USER`: Database username
- `POSTGRES_PASSWORD`: Database password
- `POSTGRES_DB`: Database name

**Redis Configuration:**
- `REDIS_HOST`: Redis server hostname
- `REDIS_PORT`: Redis server port

**Authentication:**
- `JWT_SECRET`: Secret key for JWT token signing (use a strong, random string)

**Provider API Keys (BYOK Model):**
- At least one LLM provider key (OpenAI, Anthropic, etc.)
- At least one search provider key (Tavily, Exa, etc.)

#### Setting Up API Keys

**LLM Providers:**
1. **OpenAI**: Visit [platform.openai.com](https://platform.openai.com/) to get your API key
2. **Anthropic Claude**: Visit [anthropic.com](https://www.anthropic.com/) for API access
3. **Google Gemini**: Visit [ai.google.dev](https://ai.google.dev/) for API access
4. **Other providers**: Refer to individual provider documentation

**Search Providers:**
1. **Tavily**: Visit [tavily.com](https://tavily.com/) for API access
2. **Exa**: Visit [exa.ai](https://exa.ai/) for API access
3. **Brave Search**: Visit [brave.com/search/api](https://brave.com/search/api/) for API access
4. **Serper**: Visit [serper.dev](https://serper.dev/) for API access

> For complete configuration documentation, see [Deployment Guide](docs/DEPLOYMENT.md)

### Reverse Proxy Configuration

For production deployments, configure a reverse proxy (Nginx, Apache, etc.) to handle SSL termination and route traffic to the appropriate services. See the [Deployment Guide](docs/DEPLOYMENT.md) for detailed configuration examples.

---

## ğŸ“– **Documentation**

### User Guides
- **[Quick Start Guide](docs/guides/QUICKSTART.md)** â€“ Setup, installation, and getting started

### Development
- **[Architecture](docs/ARCHITECTURE.md)** â€“ System architecture and design
- **[Deployment Guide](docs/DEPLOYMENT.md)** â€“ Production deployment instructions
- **[Contributing](CONTRIBUTING.md)** â€“ How to contribute to the project
- **[Adding LLM Providers](docs/development/ADDING_LLM_PROVIDERS.md)** â€“ Guide for adding custom LLM providers
- **[Adding Search Providers](docs/development/ADDING_SEARCH_PROVIDERS.md)** â€“ Guide for adding custom search providers

### API Reference
- **[API Documentation](docs/api/README.md)** â€“ Complete REST API and WebSocket documentation

---

## ğŸ—ï¸ **Architecture**

**Tech Stack:**
- **Frontend**: Next.js 14, React 18, TypeScript, Tailwind CSS, Radix UI
- **Backend**: NestJS, TypeORM, PostgreSQL, Redis, BullMQ
- **Infrastructure**: Docker, Docker Compose

**Key Components:**
- **API**: RESTful endpoints for providers, websets, chat, and exports
- **Real-time**: WebSocket gateway for live chat and updates
- **Queue System**: BullMQ for async enrichment jobs
- **Database**: PostgreSQL for structured data, Redis for caching & queues
- **Auth**: JWT-based authentication with role-based access control (RBAC)

---

## ğŸ¤ **Contributing**

We welcome contributions! See [CONTRIBUTING.md](CONTRIBUTING.md) for guidelines.

Want to add a new LLM or Search provider? Check the provider-specific guides:
- [Adding LLM Providers](docs/development/ADDING_LLM_PROVIDERS.md)
- [Adding Search Providers](docs/development/ADDING_SEARCH_PROVIDERS.md)

---

## ğŸ“„ **License**

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.